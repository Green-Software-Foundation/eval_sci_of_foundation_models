# Eval_SCI_of_Foundation_Models
Foundation models (e.g., BERT, GPT-3, CLIP, DALL-E 2) refer to large scale complex models that are trained on massive amounts of data and can be adapted to a wide range of downstream tasks. Despite the great potential of foundation models, they are extremely resource hungry and can generate significant carbon emissions. However, our knowledge about the carbon impact of different foundation models is very limited due to the lack of measurement tools, standard methodology, and evaluation metrics. To address this problem, this project conducts a comprehensive study on evaluating the carbon impact of several open-source foundation models (e.g., GPT-J 6B, GPT Neo 2.7B, GPT-NEO 1.3B, GPT-2) at inference stage using the Software Carbon Intensity (SCI) specification. Our study shows that (1) the quality and environmental impact of foundation models can be quantitatively measured and compared; (2) it is possible to replace carbon-intensive foundation models with more efficient ones without sacrificing model quality; and (3) deploying foundation models on more efficient hardware (e.g. GPUs) can significantly reduce SCI.

All experiments are conducted on the same server which contains an AMD Ryzen Threadripper 2950x processor (16 physical cores with hyperthreading support for 32 threads), 4 Nvidia RTX 2080TI GPUs, and 128GB of DDR4 Memory in quad channel configuration. The Setup folder contains detailed instructions on how to setup the environment for running foundation models locally.

A Python script utilizing the Pytorch and Transformers libraries is written to facilitate the testing. It selects a model, picks an option between deploying it on CPUs or GPUs, initiates the power profiling and logging collected data to CSV files at 1HZ sampling rate, then loads the model from the local storage and provides each prompt sequentially, along with two parameters: max length and temperature, records the output and, finally stops the power recording and terminates the program. The AITests folder contains the python scripts to load and run foundation models from huggingface.

Two profiling tools are developed to collect real-time information about CPU utilization, CPU power consumption as well as multiple GPUs' utilization and power consumption. To ensure the profiling tool is lightweight, we choose a sampling frequency of 1Hz, which has a negligible impact on the execution of foundation models. The profiling for GPUs is via the Nvidia Management Library (NVML). The power consumption data of the AMD Ryzen Threadripper processor is collected from the Model Specific Register (MSR) files. The Power_Profiling folder contains the source code of power profiling tools.

The Report folder contains the project proposal, project progress timeline, the experimental results, and the final report for this project.  
